# êµë³´ë¬¸ê³ ì—ì„œ ê°€ì¥ ì‘ì€ ë¶„ë¥˜ ë‹¨ìœ„ë¡œ í¬ë¡¤ë§ ëŒë¦¼
# ë¶„ë¥˜ì— í•´ë‹¹í•˜ëŠ” field codeë¥¼ field_list.txtì—ì„œ ìˆ˜ì • í›„ íŒŒì¼ ì‹¤í–‰ì‹œí‚¬ ê²ƒ

'''
pip install selenium
pip install chromedriver
pip install beautifulsoup4
pip install chromedriver_autoinstaller
pip install requests pillow

ë¨¼ì € í„°ë¯¸ë„ ë˜ëŠ” ì•„ë‚˜ì½˜ë‹¤ í”„ë¡¬í”„íŠ¸ ë˜ëŠ” ë‘˜ ë‹¤ì— ì„¤ì¹˜í•´ì£¼ì„¸ìš”.
'''

from selenium import webdriver
from chromedriver_autoinstaller import install as install_chromedriver
from bs4 import BeautifulSoup
import time
import pandas as pd
import os
import requests

# í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì¹˜ ë° ì‹¤í–‰
install_chromedriver()
driver = webdriver.Chrome()

# í´ë” ìƒì„±
os.makedirs('images', exist_ok=True)
os.makedirs('meta_data', exist_ok=True)

# ë¶„ë¥˜ ì½”ë“œ ë¦¬ìŠ¤íŠ¸ ë¡œë”©
with open("field_list.txt", "r", encoding="utf-8") as f:
    field_codes = [line.strip() for line in f if line.strip()]

# ê° ë¶„ë¥˜ ì½”ë“œì— ëŒ€í•´ í¬ë¡¤ë§
for field_code in field_codes:
    print(f"\n===== ğŸ“š ë¶„ë¥˜ ì½”ë“œ {field_code} í¬ë¡¤ë§ ì‹œì‘ =====")
    base_url = f"https://product.kyobobook.co.kr/category/KOR/{field_code}#?page={{page}}&type=all&per=50&sort=new"

    # ì²« í˜ì´ì§€ ë¡œë”©
    driver.get(base_url.format(page=1))
    time.sleep(5)
    soup = BeautifulSoup(driver.page_source, 'html.parser')

    # ë§ˆì§€ë§‰ í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ
    last_btn = soup.select_one('.btn_page_num[data-role="last"]')
    if last_btn and last_btn.text.strip().isdigit():
        last_page = int(last_btn.text.strip())
    else:
        last_page = 1
    print(f"ğŸ” ì´ í˜ì´ì§€ ìˆ˜: {last_page}")

    # ì´ë¯¸ì§€ í´ë” ìƒì„± (ë¶„ë¥˜ë³„)
    image_dir = f'images/{field_code}'
    os.makedirs(image_dir, exist_ok=True)

    # ë°ì´í„° ìˆ˜ì§‘
    data = []

    for page in range(1, last_page + 1):
        print(f"â–¶ í˜ì´ì§€ {page} í¬ë¡¤ë§ ì¤‘...")
        driver.get(base_url.format(page=page))
        time.sleep(5)
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        items = soup.select('.prod_item')

        for item in items:
            try:
                link_number = item.find('a', class_="prod_link")['href'].split("/")[-1].strip()
                title = item.find('span', class_="prod_name").get_text(strip=True)
                labels = item.find('span', class_="prod_label")
                if labels:
                    for label in labels:
                        title = title.replace(label.text.strip(), '')

                author_tag = item.find('span', class_="prod_author")
                if author_tag:
                    author_link = author_tag.find('a')
                    author = author_link.text.strip() if author_link else author_tag.text.strip()
                    if not author:
                        author = ""
                else:
                    author = ""

                raw_intro = item.select_one('.prod_introduction')
                if raw_intro:
                    intro_clean = raw_intro.text.strip().replace('\n', ' ').replace('\r', ' ')
                    intro_truncated = (intro_clean[:100] + '...') if len(intro_clean) > 100 else intro_clean
                else:
                    intro_truncated = ""

                review_tag = item.select_one('.review_klover_text')
                review = float(review_tag.text.strip()) if review_tag else None

                # ì´ë¯¸ì§€ ì €ì¥
                img_tag = item.select_one('.img_box img')
                if img_tag:
                    img_url = img_tag.get('src') or img_tag.get('data-src')
                    if img_url:
                        img_data = requests.get(img_url).content
                        with open(f'{image_dir}/{link_number}.jpg', 'wb') as f:
                            f.write(img_data)

                # ë°ì´í„° ì €ì¥
                data.append((link_number, title, author, intro_truncated, review))

            except Exception as e:
                print(f"[â—ì˜¤ë¥˜] {e}")
                continue

    # ë¶„ë¥˜ë³„ CSV ì €ì¥
    df = pd.DataFrame(data, columns=['Num', 'Title', 'Author', 'Introduction', 'Review'])
    df.to_csv(f'meta_data/books_{field_code}.csv', index=False, encoding='utf-8-sig')
    print(f"âœ… ì €ì¥ ì™„ë£Œ: meta_data/books_{field_code}.csv")

driver.quit()
print("ğŸ‰ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ")
